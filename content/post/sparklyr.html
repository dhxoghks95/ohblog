---
title: "Sparklyr로 R에서 Spark 분산처리 활용해 기계학습 진행하기 - 1. sparklyr 소개"
author : 오태환
date: 2020-08-30T17:15:21+09:00
tags : ["R", "Spark", "sparklyr", "dplyr", "tidyverse", "hadoop", "machine learning"]
---



<div id="sparklyr로-r에서-spark-분산처리-활용해-기계학습-진행하기" class="section level1">
<h1><strong>Sparklyr로 R에서 Spark 분산처리 활용해 기계학습 진행하기</strong></h1>
</div>
<div id="sparklyr-소개" class="section level1">
<h1><strong>1. sparklyr 소개</strong></h1>
<p>이 포스트는 Tidyverse Korea의</p>
<p><a href="https://statkclee.github.io/bigdata/ml-sparklyr.html">sparklyr, dplyr, 그리고 기계학습</a> 문서를 토대로 작성되었습니다.</p>
</div>
<div id="로컬-컴퓨터에-스파크-설치하기" class="section level1">
<h1>0) 로컬 컴퓨터에 스파크 설치하기</h1>
<p><a href="https://statkclee.github.io/bigdata/ds-sparklyr.html">로컬 컴퓨터에 스파크 설치하기</a></p>
<p>를 보고 설치하면 된다. 윈도우의 경우 주의할 점은 환경변수 설정! 참고로 환경변수 경로를 변경할 때, 컴퓨터를 다시 시작해야 적용된다 ㅠㅠ 이것 때문에 하루종일 고생했다…</p>
</div>
<div id="rstudio에서-sparklyr-실행하기" class="section level1">
<h1>1) Rstudio에서 sparklyr 실행하기</h1>
<p>sparklyr이라는 이름에서 눈치챘을 수도 있겠지만, 이 패키지는 Spark에서 dplyr을 사용할 수 있게 하는 패키지입니다.</p>
<p><a href="https://github.com/dhxoghks95/2020_jeju_creditcard">제주 빅데이터 경진대회</a>를 준비하면서 가장 많이 궁금했던 점이 “R로 어떻게 큰 데이터를 다룰 수 있을까” 라는 질문이었습니다. 분명 R은 Tidyverse를 필두로 한 강력한 데이터 정제 패키지를 가지고 있습니다. 하지만 데이터가 조금만 커져도 처리 속도가 굉장히 느려진다는 단점이 있죠. 그 단점을 해결하기 위해 만들어진 것이 바로 Spark의 빠른 분산 처리 시스템과 R의 데이터 정제 능력을 결합한 Sparkly 패키지입니다. 이를 활용함으로서 빅데이터를 R에서도 다룰 수 있게 됩니다.</p>
<pre class="r"><code># install.packages(&quot;sparklyr&quot;)
# install.packages(&quot;tidyverse&quot;)

library(sparklyr)</code></pre>
<pre><code>## Warning: 패키지 &#39;sparklyr&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## Warning: 패키지 &#39;tidyverse&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## -- Attaching packages ----------------------------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## √ ggplot2 3.3.1     √ purrr   0.3.4
## √ tibble  3.0.1     √ dplyr   1.0.2
## √ tidyr   1.1.0     √ stringr 1.4.0
## √ readr   1.3.1     √ forcats 0.5.0</code></pre>
<pre><code>## Warning: 패키지 &#39;tibble&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## Warning: 패키지 &#39;tidyr&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## Warning: 패키지 &#39;purrr&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## Warning: 패키지 &#39;dplyr&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## Warning: 패키지 &#39;forcats&#39;는 R 버전 3.6.3에서 작성되었습니다</code></pre>
<pre><code>## -- Conflicts -------------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x purrr::invoke() masks sparklyr::invoke()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p>우선 패키지를 설치 후 Import합니다</p>
<p>그리고 스파크 클러스터에 연결합시다.</p>
<pre class="r"><code>sc &lt;-spark_connect(master=&quot;local&quot;)

# 자 이제 이 sc(spark cluster)를 통해 스파크에 접속할 것입니다.


spark_version(sc=sc)</code></pre>
<pre><code>## [1] &#39;3.0.0&#39;</code></pre>
<pre class="r"><code># 버전이 잘 나오면 잘 연결된것입니다.

# 스파크 연결해제
# spark_disconnect(sc=sc)</code></pre>
</div>
<div id="spark에-csv파일-불러오기" class="section level1">
<h1>2) Spark에 csv파일 불러오기</h1>
<p>sparklyr에도 tidyverse의 readr::read_csv()와 같이 데이터를 불러오는 함수가 있습니다. spark_read_csv()함수죠. 참고로 iris와 같이 R에 내장되어 있는 데이터프레임의 경우에는 copy_to()함수를 쓰면 됩니다. 우리는 <a href="https://www.kaggle.com/usdot/flight-delays">kaggle 2015 Flight Delays and Cancellations</a>에서 다운받을 수 있는 filight.csv파일을 통해 실습을 진행하도록 하겠습니다.</p>
<pre class="r"><code>flight_tbls = spark_read_csv(sc, name = &quot;flights&quot;, path = &quot;C:/Users/dhxog/Downloads/810_1496_bundle_archive/flights.csv&quot;)
# sc로 연결할 spark cluster를 넣고, table의 이름을 지어서 name으로 넣습니다. 그리고 path에 경로를 넣으면 됩니다.

# 내장 데이터프레임의 경우

# iris_tbls = copy_to(sc, iris)

src_tbls(sc)</code></pre>
<pre><code>## [1] &quot;flights&quot;</code></pre>
<p>sc에 flights라는 이름의 데이터 프레임 테이블이 들어온 것을 볼 수 있습니다!</p>
<div class="figure">
<img src="https://user-images.githubusercontent.com/57588650/91659225-aa24e880-eb09-11ea-9f2c-648375a83a64.png" alt="" />
<p class="caption">spark_cluster</p>
</div>
<p>출처 : <a href="https://statkclee.github.io/bigdata/ml-sparklyr.html" class="uri">https://statkclee.github.io/bigdata/ml-sparklyr.html</a></p>
<p>이와 같이 로컬 컴퓨터에 있는 flights.csv를 Spark Cluster에 업로드 시킨것으로 이해하시면 됩니다.</p>
</div>
<div id="spark-cluster에-있는-파일을-tibble로-불러오기" class="section level1">
<h1>3) Spark Cluster에 있는 파일을 Tibble로 불러오기</h1>
<p>자 이전 과정에서 우리는 Spark Cluster에 csv 파일을 올렸습니다. 이제 그 데이터를 어떻게 활용해야 할까요? 바로 tibble로 가져오는 것입니다. tibble은 매우 빠르고 작은 데이터를 반환하기 때문에 데이터를 분석하기에 굉장히 용이합니다. 그러면서 실제 데이터는 Spark Cluster에 존재하게 됩니다.</p>
<pre class="r"><code>flights_tbl = tbl(sc, &quot;flights&quot;)
# Spark Cluster에서 &quot;flights&quot;라는 이름의 dataframe을 tibble로 가져옵니다

dim(flights_tbl)</code></pre>
<pre><code>## [1] NA 31</code></pre>
<p>불러온 데이터의 크기를 확인해봅시다</p>
<pre class="r"><code>#install.packages(&quot;pryr&quot;)
pryr::object_size(flights_tbl)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;pryr&#39;:
##   method      from
##   print.bytes Rcpp</code></pre>
<pre><code>## 55.2 kB</code></pre>
<p>pryr 패키지의 object_size함수를 사용하면 데이터의 크기를 알 수 있습니다</p>
<p>자 이제 불러온 데이터를 조금 봐볼까요?</p>
<pre class="r"><code>print(flights_tbl, n = 10)</code></pre>
<pre><code>## # Source: spark&lt;flights&gt; [?? x 31]
##     YEAR MONTH   DAY DAY_OF_WEEK AIRLINE FLIGHT_NUMBER TAIL_NUMBER
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt; &lt;chr&gt;           &lt;int&gt; &lt;chr&gt;      
##  1  2015     1     1           4 AS                 98 N407AS     
##  2  2015     1     1           4 AA               2336 N3KUAA     
##  3  2015     1     1           4 US                840 N171US     
##  4  2015     1     1           4 AA                258 N3HYAA     
##  5  2015     1     1           4 AS                135 N527AS     
##  6  2015     1     1           4 DL                806 N3730B     
##  7  2015     1     1           4 NK                612 N635NK     
##  8  2015     1     1           4 US               2013 N584UW     
##  9  2015     1     1           4 AA               1112 N3LAAA     
## 10  2015     1     1           4 DL               1173 N826DN     
## # ... with more rows, and 24 more variables: ORIGIN_AIRPORT &lt;chr&gt;,
## #   DESTINATION_AIRPORT &lt;chr&gt;, SCHEDULED_DEPARTURE &lt;int&gt;, DEPARTURE_TIME &lt;int&gt;,
## #   DEPARTURE_DELAY &lt;int&gt;, TAXI_OUT &lt;int&gt;, WHEELS_OFF &lt;int&gt;,
## #   SCHEDULED_TIME &lt;int&gt;, ELAPSED_TIME &lt;int&gt;, AIR_TIME &lt;int&gt;, DISTANCE &lt;int&gt;,
## #   WHEELS_ON &lt;int&gt;, TAXI_IN &lt;int&gt;, SCHEDULED_ARRIVAL &lt;int&gt;,
## #   ARRIVAL_TIME &lt;int&gt;, ARRIVAL_DELAY &lt;int&gt;, DIVERTED &lt;int&gt;, CANCELLED &lt;int&gt;,
## #   CANCELLATION_REASON &lt;chr&gt;, AIR_SYSTEM_DELAY &lt;int&gt;, SECURITY_DELAY &lt;int&gt;,
## #   AIRLINE_DELAY &lt;int&gt;, LATE_AIRCRAFT_DELAY &lt;int&gt;, WEATHER_DELAY &lt;int&gt;</code></pre>
<p>자료구조도 확인해봅시다</p>
<pre class="r"><code>glimpse(flights_tbl)</code></pre>
<pre><code>## Rows: ??
## Columns: 31
## Database: spark_connection
## $ YEAR                &lt;int&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,...
## $ MONTH               &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...
## $ DAY                 &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...
## $ DAY_OF_WEEK         &lt;int&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,...
## $ AIRLINE             &lt;chr&gt; &quot;AS&quot;, &quot;AA&quot;, &quot;US&quot;, &quot;AA&quot;, &quot;AS&quot;, &quot;DL&quot;, &quot;NK&quot;, &quot;US&quot;,...
## $ FLIGHT_NUMBER       &lt;int&gt; 98, 2336, 840, 258, 135, 806, 612, 2013, 1112, ...
## $ TAIL_NUMBER         &lt;chr&gt; &quot;N407AS&quot;, &quot;N3KUAA&quot;, &quot;N171US&quot;, &quot;N3HYAA&quot;, &quot;N527AS...
## $ ORIGIN_AIRPORT      &lt;chr&gt; &quot;ANC&quot;, &quot;LAX&quot;, &quot;SFO&quot;, &quot;LAX&quot;, &quot;SEA&quot;, &quot;SFO&quot;, &quot;LAS&quot;...
## $ DESTINATION_AIRPORT &lt;chr&gt; &quot;SEA&quot;, &quot;PBI&quot;, &quot;CLT&quot;, &quot;MIA&quot;, &quot;ANC&quot;, &quot;MSP&quot;, &quot;MSP&quot;...
## $ SCHEDULED_DEPARTURE &lt;int&gt; 5, 10, 20, 20, 25, 25, 25, 30, 30, 30, 30, 35, ...
## $ DEPARTURE_TIME      &lt;int&gt; 2354, 2, 18, 15, 24, 20, 19, 44, 19, 33, 24, 27...
## $ DEPARTURE_DELAY     &lt;int&gt; -11, -8, -2, -5, -1, -5, -6, 14, -11, 3, -6, -8...
## $ TAXI_OUT            &lt;int&gt; 21, 12, 16, 15, 11, 18, 11, 13, 17, 12, 12, 21,...
## $ WHEELS_OFF          &lt;int&gt; 15, 14, 34, 30, 35, 38, 30, 57, 36, 45, 36, 48,...
## $ SCHEDULED_TIME      &lt;int&gt; 205, 280, 286, 285, 235, 217, 181, 273, 195, 22...
## $ ELAPSED_TIME        &lt;int&gt; 194, 279, 293, 281, 215, 230, 170, 249, 193, 20...
## $ AIR_TIME            &lt;int&gt; 169, 263, 266, 258, 199, 206, 154, 228, 173, 18...
## $ DISTANCE            &lt;int&gt; 1448, 2330, 2296, 2342, 1448, 1589, 1299, 2125,...
## $ WHEELS_ON           &lt;int&gt; 404, 737, 800, 748, 254, 604, 504, 745, 529, 65...
## $ TAXI_IN             &lt;int&gt; 4, 4, 11, 8, 5, 6, 5, 8, 3, 5, 4, 7, 4, 5, 4, 4...
## $ SCHEDULED_ARRIVAL   &lt;int&gt; 430, 750, 806, 805, 320, 602, 526, 803, 545, 71...
## $ ARRIVAL_TIME        &lt;int&gt; 408, 741, 811, 756, 259, 610, 509, 753, 532, 65...
## $ ARRIVAL_DELAY       &lt;int&gt; -22, -9, 5, -9, -21, 8, -17, -10, -13, -15, -30...
## $ DIVERTED            &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ CANCELLED           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ CANCELLATION_REASON &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ AIR_SYSTEM_DELAY    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ SECURITY_DELAY      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ AIRLINE_DELAY       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ LATE_AIRCRAFT_DELAY &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ WEATHER_DELAY       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...</code></pre>
</div>
<div id="불러온-데이터를-dplyr로-만져보기" class="section level1">
<h1>4) 불러온 데이터를 dplyr로 만져보기</h1>
<p>자 이제 Spark DataFrame을 tbl 명령어를 사용해 tibble로 불러왔으니 dplyr패키지의 멋진 함수들을 모두 쓸 수 있습니다.
하나씩 써보죠!</p>
<div id="select" class="section level2">
<h2>4-1) select</h2>
<pre class="r"><code>flights_tbl %&gt;% dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL)</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 6]
##     YEAR MONTH   DAY AIRLINE FLIGHT_NUMBER SCHEDULED_ARRIVAL
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;int&gt;             &lt;int&gt;
##  1  2015     1     1 AS                 98               430
##  2  2015     1     1 AA               2336               750
##  3  2015     1     1 US                840               806
##  4  2015     1     1 AA                258               805
##  5  2015     1     1 AS                135               320
##  6  2015     1     1 DL                806               602
##  7  2015     1     1 NK                612               526
##  8  2015     1     1 US               2013               803
##  9  2015     1     1 AA               1112               545
## 10  2015     1     1 DL               1173               711
## # ... with more rows</code></pre>
</div>
<div id="filter" class="section level2">
<h2>4-2) filter</h2>
<pre class="r"><code>flights_tbl %&gt;% dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% dplyr::filter(AIRLINE == &#39;AA&#39;)</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 6]
##     YEAR MONTH   DAY AIRLINE FLIGHT_NUMBER SCHEDULED_ARRIVAL
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;int&gt;             &lt;int&gt;
##  1  2015     1     1 AA               2336               750
##  2  2015     1     1 AA                258               805
##  3  2015     1     1 AA               1112               545
##  4  2015     1     1 AA               1674               803
##  5  2015     1     1 AA                371               938
##  6  2015     1     1 AA                115               851
##  7  2015     1     1 AA               2392               707
##  8  2015     1     1 AA               2211               726
##  9  2015     1     1 AA               2459               500
## 10  2015     1     1 AA               1323               613
## # ... with more rows</code></pre>
</div>
<div id="arrange" class="section level2">
<h2>4-3) arrange</h2>
<pre class="r"><code>flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% 
  dplyr::filter(AIRLINE == &#39;AA&#39;) %&gt;%
  dplyr::arrange(desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL)</code></pre>
<pre><code>## # Source:     spark&lt;?&gt; [?? x 6]
## # Ordered by: desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL
##     YEAR MONTH   DAY AIRLINE FLIGHT_NUMBER SCHEDULED_ARRIVAL
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;int&gt;             &lt;int&gt;
##  1  2015    12     9 AA               2625              1024
##  2  2015    12     1 AA               2625              1024
##  3  2015    12     8 AA               2625              1024
##  4  2015    12     2 AA               2625              1024
##  5  2015    12     4 AA               2625              1024
##  6  2015    12     6 AA               2625              1024
##  7  2015    12     7 AA               2625              1024
##  8  2015    12     5 AA               2625              1024
##  9  2015    12    10 AA               2625              1024
## 10  2015    12     3 AA               2625              1024
## # ... with more rows</code></pre>
</div>
<div id="mutate" class="section level2">
<h2>4-4) mutate</h2>
<pre class="r"><code>flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% 
  dplyr::filter(AIRLINE == &#39;AA&#39;) %&gt;%
  dplyr::arrange(desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL) %&gt;%
  dplyr::mutate(AIR_NUMBER = paste0(AIRLINE, &#39;_&#39;, FLIGHT_NUMBER))</code></pre>
<pre><code>## # Source:     spark&lt;?&gt; [?? x 7]
## # Ordered by: desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL
##     YEAR MONTH   DAY AIRLINE FLIGHT_NUMBER SCHEDULED_ARRIVAL AIR_NUMBER
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;int&gt;             &lt;int&gt; &lt;chr&gt;     
##  1  2015    12     9 AA               2625              1024 AA_2625   
##  2  2015    12     1 AA               2625              1024 AA_2625   
##  3  2015    12     8 AA               2625              1024 AA_2625   
##  4  2015    12     2 AA               2625              1024 AA_2625   
##  5  2015    12     4 AA               2625              1024 AA_2625   
##  6  2015    12     6 AA               2625              1024 AA_2625   
##  7  2015    12     7 AA               2625              1024 AA_2625   
##  8  2015    12     5 AA               2625              1024 AA_2625   
##  9  2015    12    10 AA               2625              1024 AA_2625   
## 10  2015    12     3 AA               2625              1024 AA_2625   
## # ... with more rows</code></pre>
</div>
<div id="summerize" class="section level2">
<h2>4-5) summerize</h2>
<pre class="r"><code>flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% 
  dplyr::filter(AIRLINE == &#39;AA&#39;) %&gt;%
  dplyr::arrange(desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL) %&gt;%
  dplyr::mutate(AIR_NUMBER = paste0(AIRLINE, &#39;_&#39;, FLIGHT_NUMBER)) %&gt;%
  dplyr::summarise(MEAN_ARRIVAL = mean(SCHEDULED_ARRIVAL))</code></pre>
<pre><code>## Warning: Missing values are always removed in SQL.
## Use `mean(x, na.rm = TRUE)` to silence this warning
## This warning is displayed only once per session.</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 1]
##   MEAN_ARRIVAL
##          &lt;dbl&gt;
## 1        1512.</code></pre>
</div>
</div>
<div id="dplyr-고급-기능-사용하기" class="section level1">
<h1>5) dplyr 고급 기능 사용하기</h1>
<p>앞에서 사용한 함수들 안에 parameter를 더 넣고, count, group_by등의 함수도 쓸 수 있습니다.</p>
<div id="select---starts_with" class="section level2">
<h2>5-1) select - starts_with</h2>
<pre class="r"><code>flights_tbl %&gt;% dplyr::select(YEAR, MONTH, DAY, FLIGHT_NUMBER, starts_with(&quot;AIR&quot;))</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 8]
##     YEAR MONTH   DAY FLIGHT_NUMBER AIRLINE AIR_TIME AIR_SYSTEM_DELAY
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt; &lt;chr&gt;      &lt;int&gt;            &lt;int&gt;
##  1  2015     1     1            98 AS           169               NA
##  2  2015     1     1          2336 AA           263               NA
##  3  2015     1     1           840 US           266               NA
##  4  2015     1     1           258 AA           258               NA
##  5  2015     1     1           135 AS           199               NA
##  6  2015     1     1           806 DL           206               NA
##  7  2015     1     1           612 NK           154               NA
##  8  2015     1     1          2013 US           228               NA
##  9  2015     1     1          1112 AA           173               NA
## 10  2015     1     1          1173 DL           186               NA
## # ... with more rows, and 1 more variable: AIRLINE_DELAY &lt;int&gt;</code></pre>
<p>select 함수 안에 start_with(“AIR”)를 쓰면 AIR로 시작하는 모든 column들을 선택할 수 있습니다</p>
</div>
<div id="distinct" class="section level2">
<h2>5-2) distinct</h2>
<pre class="r"><code>flights_tbl %&gt;% distinct(AIRLINE)</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 1]
##    AIRLINE
##    &lt;chr&gt;  
##  1 WN     
##  2 VX     
##  3 DL     
##  4 OO     
##  5 B6     
##  6 F9     
##  7 NK     
##  8 US     
##  9 EV     
## 10 UA     
## # ... with more rows</code></pre>
<p>distinct로 unique값을 출력할 수 있습니다</p>
</div>
<div id="count" class="section level2">
<h2>5-3) count</h2>
<pre class="r"><code>flights_tbl %&gt;% dplyr::count(AIRLINE, sort = TRUE)</code></pre>
<pre><code>## # Source:     spark&lt;?&gt; [?? x 2]
## # Ordered by: desc(n)
##    AIRLINE       n
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 WN      1261855
##  2 DL       875881
##  3 AA       725984
##  4 OO       588353
##  5 EV       571977
##  6 UA       515723
##  7 MQ       294632
##  8 B6       267048
##  9 US       198715
## 10 AS       172521
## # ... with more rows</code></pre>
<p>count함수를 사용하면 factor들의 갯수를 구할 수 있습니다.</p>
</div>
<div id="group_by" class="section level2">
<h2>5-4) group_by</h2>
<pre class="r"><code>flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% 
  dplyr::arrange(desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL) %&gt;%
  dplyr::mutate(AIR_NUMBER = paste0(AIRLINE, &#39;_&#39;, FLIGHT_NUMBER)) %&gt;%
  dplyr::group_by(AIRLINE) %&gt;%
  dplyr::summarise(MEAN_ARRIVAL = mean(SCHEDULED_ARRIVAL))</code></pre>
<pre><code>## # Source: spark&lt;?&gt; [?? x 2]
##    AIRLINE MEAN_ARRIVAL
##    &lt;chr&gt;          &lt;dbl&gt;
##  1 WN             1494.
##  2 VX             1574.
##  3 DL             1512.
##  4 OO             1480.
##  5 B6             1472.
##  6 F9             1511.
##  7 NK             1478.
##  8 US             1496.
##  9 EV             1482.
## 10 UA             1484.
## # ... with more rows</code></pre>
</div>
<div id="explain" class="section level2">
<h2>5-5) explain</h2>
<p>dplyr은 SQL쿼리를 참고해서 만들어진 함수입니다. explain() 함수를 사용하면 사용한 dplyr함수와 동일한 값을 반환하는 SQL 쿼리를 출력할 수 있습니다.</p>
<pre class="r"><code>flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, AIRLINE, FLIGHT_NUMBER, SCHEDULED_ARRIVAL) %&gt;% 
  dplyr::arrange(desc(FLIGHT_NUMBER), SCHEDULED_ARRIVAL) %&gt;%
  dplyr::group_by(AIRLINE) %&gt;%
  dplyr::summarise(MEAN_ARRIVAL = mean(SCHEDULED_ARRIVAL)) %&gt;%
  explain()</code></pre>
<pre><code>## &lt;SQL&gt;
## SELECT `AIRLINE`, AVG(`SCHEDULED_ARRIVAL`) AS `MEAN_ARRIVAL`
## FROM (SELECT *
## FROM (SELECT `YEAR`, `MONTH`, `DAY`, `AIRLINE`, `FLIGHT_NUMBER`, `SCHEDULED_ARRIVAL`
## FROM `flights`) `dbplyr_061`
## ORDER BY `FLIGHT_NUMBER` DESC, `SCHEDULED_ARRIVAL`) `dbplyr_062`
## GROUP BY `AIRLINE`
## 
## &lt;PLAN&gt;</code></pre>
<pre><code>## == Physical Plan ==
## *(2) HashAggregate(keys=[AIRLINE#41], functions=[avg(cast(SCHEDULED_ARRIVAL#57 as bigint))])
## +- Exchange hashpartitioning(AIRLINE#41, 8), true, [id=#714]
##    +- *(1) HashAggregate(keys=[AIRLINE#41], functions=[partial_avg(cast(SCHEDULED_ARRIVAL#57 as bigint))])
##       +- Scan In-memory table `flights` [AIRLINE#41, SCHEDULED_ARRIVAL#57]
##             +- InMemoryRelation [YEAR#37, MONTH#38, DAY#39, DAY_OF_WEEK#40, AIRLINE#41, FLIGHT_NUMBER#42, TAIL_NUMBER#43, ORIGIN_AIRPORT#44, DESTINATION_AIRPORT#45, SCHEDULED_DEPARTURE#46, DEPARTURE_TIME#47, DEPARTURE_DELAY#48, TAXI_OUT#49, WHEELS_OFF#50, SCHEDULED_TIME#51, ELAPSED_TIME#52, AIR_TIME#53, DISTANCE#54, WHEELS_ON#55, TAXI_IN#56, SCHEDULED_ARRIVAL#57, ARRIVAL_TIME#58, ARRIVAL_DELAY#59, DIVERTED#60, ... 7 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)
##                   +- FileScan csv [YEAR#37,MONTH#38,DAY#39,DAY_OF_WEEK#40,AIRLINE#41,FLIGHT_NUMBER#42,TAIL_NUMBER#43,ORIGIN_AIRPORT#44,DESTINATION_AIRPORT#45,SCHEDULED_DEPARTURE#46,DEPARTURE_TIME#47,DEPARTURE_DELAY#48,TAXI_OUT#49,WHEELS_OFF#50,SCHEDULED_TIME#51,ELAPSED_TIME#52,AIR_TIME#53,DISTANCE#54,WHEELS_ON#55,TAXI_IN#56,SCHEDULED_ARRIVAL#57,ARRIVAL_TIME#58,ARRIVAL_DELAY#59,DIVERTED#60,... 7 more fields] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/dhxog/Downloads/810_1496_bundle_archive/flights.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;YEAR:int,MONTH:int,DAY:int,DAY_OF_WEEK:int,AIRLINE:string,FLIGHT_NUMBER:int,TAIL_NUMBER:st...</code></pre>
<pre class="r"><code>#install.packages(&quot;DBI&quot;)
DBI::dbGetQuery(sc, 
&quot;SELECT `AIRLINE`, AVG(`SCHEDULED_ARRIVAL`) AS `MEAN_ARRIVAL`
FROM (SELECT *
FROM (SELECT `YEAR`, `MONTH`, `DAY`, `AIRLINE`, `FLIGHT_NUMBER`, `SCHEDULED_ARRIVAL`
FROM `flights`) `dbplyr_053`
ORDER BY `FLIGHT_NUMBER` DESC, `SCHEDULED_ARRIVAL`) `dbplyr_054`
GROUP BY `AIRLINE`&quot;)</code></pre>
<pre><code>##    AIRLINE MEAN_ARRIVAL
## 1       WN     1493.669
## 2       VX     1574.010
## 3       DL     1511.756
## 4       OO     1479.880
## 5       B6     1472.204
## 6       F9     1511.008
## 7       NK     1478.249
## 8       US     1496.494
## 9       EV     1482.230
## 10      UA     1483.909
## 11      MQ     1468.390
## 12      AS     1516.481
## 13      AA     1512.058
## 14      HA     1431.423</code></pre>
<p>위와 같이 DBI 패키지의 dbGetQuery함수로 위에서 출력한 SQL 쿼리를 복사 붙여넣기함으로써 Spark Cluster에서 SQL 쿼리로 직접 조작된 데이터를 가져올 수 있습니다.</p>
</div>
</div>
<div id="데이터프레임-변환과-중간결과-저장" class="section level1">
<h1>6) 데이터프레임 변환과 중간결과 저장</h1>
<p>지금까지 spark_read_csv() 또는 copy_to()를 통해 Spark Cluster에 R 데이터프레임을 보내고 Spark Cluster 데이터프레임을 dplyr을 통해 출력해보았습니다.
반대로 Spark Cluster 데이터프레임을 R 데이터프레임으로 변환하려면 collect() 함수를 사용해야합니다.</p>
<p>dplyr 파이프 연산자를 통해 데이터를 조작할 때, 코드가 길어질 경우에는 중간에 세션이 다운되는 경우가 흔합니다. 그렇기 때문에 compute 함수를 사용해 Spark Cluster에 중간결과를 저장해 안정적으로 후속작업을 진행할 수 있습니다.</p>
<div id="r-데이터프레임으로-변환" class="section level2">
<h2>6-1) R 데이터프레임으로 변환</h2>
<pre class="r"><code>flights_df = flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, starts_with(&quot;AIR&quot;)) %&gt;%
  collect()

class(flights_df)</code></pre>
<pre><code>## [1] &quot;tbl_df&quot;     &quot;tbl&quot;        &quot;data.frame&quot;</code></pre>
</div>
<div id="중간결과-저장" class="section level2">
<h2>6-2) 중간결과 저장</h2>
<pre class="r"><code>flights_air = flights_tbl %&gt;% 
  dplyr::select(YEAR, MONTH, DAY, starts_with(&quot;AIR&quot;)) %&gt;%
  compute(&quot;flight_air&quot;)

src_tbls(sc)</code></pre>
<pre><code>## [1] &quot;flight_air&quot; &quot;flights&quot;</code></pre>
<p>Spark Cluster에 flight_air라고 이름붙인 중간결과가 업로드 된 것을 볼 수 있습니다.</p>
</div>
</div>
